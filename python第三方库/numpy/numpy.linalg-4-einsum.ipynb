{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cell\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einsum\n",
    "\n",
    "- [numpy.sum](https://numpy.org/doc/stable/reference/generated/numpy.sum.html)\n",
    "- [numpy.einsum](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html)\n",
    "\n",
    "`einsum`: Evaluates the Einstein summation convention on the operands.\n",
    "\n",
    "Using the Einstein summation convention, many common multi-dimensional, linear algebraic array operations can be represented in a simple fashion. In implicit mode *einsum* computes these values.\n",
    "\n",
    "The subscripts string is a <u>comma-separated</u> list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed.\n",
    "\n",
    "---\n",
    "\n",
    "[Understanding NumPy's einsum](https://stackoverflow.com/questions/26089893/understanding-numpys-einsum)\n",
    "\n",
    "[A basic introduction to NumPy's einsum](https://ajcr.net/Basic-guide-to-einsum/) @ [1](http://www.atyun.com/32288.html)、[2](https://blog.popkx.com/A-basic-introduction-to-NumPy-s-einsum/)  \n",
    "[Einsum Is All You Need: NumPy, PyTorch and TensorFlow](https://www.youtube.com/watch?v=pkVwUVEHmfI)  \n",
    "[EINSUM IS ALL YOU NEED - EINSTEIN SUMMATION IN DEEP LEARNING](https://rockt.github.io/2018/04/30/einsum)  \n",
    "\n",
    "[一个函数打天下，einsum](https://zhuanlan.zhihu.com/p/71639781)  \n",
    "[如何理解和使用NumPy.einsum？](https://zhuanlan.zhihu.com/p/27739282)  \n",
    "[Python 學習筆記｜numpy.einsum用法](https://medium.com/programming-with-data/python-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98-numpy-einsum%E7%94%A8%E6%B3%95-2169af18c475)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implicit mode\n",
    "\n",
    "`np.einsum('i,i', a, b)` is equivalent to `np.inner(a,b)`.\n",
    "\n",
    "- 单字母下标只能索引1D vector，将a和b对应位置元素相乘再求和，即求点/内积。\n",
    "\n",
    "`np.einsum('ij,ij', a, b)` is equivalent to `tensordot(a,b,axes=([0,1],[0,1]))`。\n",
    "\n",
    "- 两个二维索引名称和顺序完全一致，表示相同维度相同位置相乘再求和（shape overlap multiply sum）。\n",
    "\n",
    "`np.einsum('ij,jk', a, b)` describes traditional matrix multiplication and is equivalent to `np.matmul(a,b)`.\n",
    "\n",
    "- 交汇索引`j`为a的第二维、b的第一维，相当于 `tensordot(axes=(1,0))`，等价于普通的矩阵乘法。\n",
    "\n",
    "![matmul_reduce](https://ajcr.net/images/matrix_mul_reduce.png)\n",
    "\n",
    "`np.einsum('ij,jh', a, b)` returns the **transpose** of the multiplication since subscript ‘h’ precedes subscript ‘i’.\n",
    "\n",
    "- 正常脚标顺序的表达式 np.einsum('ij,jk', a, b) 计算结果为 `ik`，此处结果为 `ih`，相当于对结果进行转置。\n",
    "\n",
    "`np.einsum('ii', a)` is equivalent to `np.trace(a)`.\n",
    "\n",
    "- `ii` 表示横纵索引一样，相当于对角线元素相加，整体等价于 trace。\n",
    "\n",
    "`np.einsum('ij', a)` doesn’t affect a 2D array, while `np.einsum('ji', a)` takes its **transpose**.\n",
    "\n",
    "- `ji` 将横纵坐标调换顺序，相当于求其转置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector einsum\n",
    "\n",
    "a=np.arange(1,5)\n",
    "b=np.arange(5,9)\n",
    "es_dot = np.einsum('i,i', a, b)\n",
    "print('es_dot:\\n', es_dot)\n",
    "\n",
    "# 对角线相加(trace)\n",
    "c = np.arange(9).reshape(3,3)\n",
    "print('c.diagnoal():\\n', c.diagonal())\n",
    "es_trace = np.einsum('ii', c)\n",
    "print('es_trace:\\n', es_trace)\n",
    "\n",
    "# 求转置\n",
    "es_T = np.einsum('ji', c)\n",
    "print('es_T:\\n', es_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D einsum\n",
    "\n",
    "# sum all elements\n",
    "a = np.arange(6).reshape(2, 3)\n",
    "es_sum = np.einsum('ij->', a)\n",
    "print('es_sum:\\n', es_sum)\n",
    "\n",
    "# sum columns\n",
    "es_sum_col = np.einsum('ij->j', a)\n",
    "print('es_sum_col:\\n', es_sum_col)\n",
    "\n",
    "# sum rows\n",
    "es_sum_row = np.einsum('ij->i', a)\n",
    "print('es_sum_row:\\n', es_sum_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D einsum\n",
    "\n",
    "a = np.array([1,2,3,4]).reshape(2,2)\n",
    "b = np.array([5,6,7,8]).reshape(2,2)\n",
    "es_vdot = np.einsum('ij,ij', a, b)\n",
    "print('es_vdot:\\n', es_vdot)\n",
    "es_inner = np.einsum('ij,jk', a, b)\n",
    "print('es_inner:\\n', es_inner)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explicit mode\n",
    "\n",
    "In explicit mode the output can be directly controlled by specifying output subscript labels. This requires the identifier ‘`->`’ as well as the list of output subscript labels. This feature increases the flexibility of the function since summing can be disabled or forced when required.\n",
    "\n",
    "The call `np.einsum('i->', a)` is like `np.sum(a, axis=-1)`, and `np.einsum('ii->i', a)` is like `np.diag(a)`. The difference is that einsum **does not** allow broadcasting by default.\n",
    "\n",
    "Additionally `np.einsum('ij,jh->ih', a, b)` directly specifies the order of the output subscript labels and therefore returns matrix multiplication, unlike the example above in implicit mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit\n",
    "\n",
    "# 单字母小标对应1D vector\n",
    "a = np.array([1,2,3,4])\n",
    "es1 = np.einsum('i->', a)\n",
    "print('es1:\\n', es1)\n",
    "\n",
    "b = np.array([5,6,7,8]).reshape(2,2)\n",
    "# ValueError: operand has more dimensions than subscripts given\n",
    "# es2 = np.einsum('i->', b)\n",
    "# ellipsis provided to broadcast the extra dimensions.\n",
    "es2 = np.einsum('...i->...', b)\n",
    "print('es2:\\n', es2)\n",
    "\n",
    "# 对角线向量，二维索引变一维索引\n",
    "es3 = np.einsum('ii->i', b)\n",
    "print('es3:\\n', es3)\n",
    "\n",
    "# 将a变成2D\n",
    "a = np.array([1,2,3,4]).reshape(2,2)\n",
    "es4 = np.einsum('ij,jh->ih', a, b)\n",
    "print('es4:\\n', es4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "\n",
    "# multiply element-wise and then sum along axis 1 (the rows of the array)\n",
    "a = np.array([0, 1, 2])\n",
    "b = np.array([[ 0,  1,  2,  3],\n",
    "              [ 4,  5,  6,  7],\n",
    "              [ 8,  9, 10, 11]])\n",
    "c = (a[:, np.newaxis] * b).sum(axis=1)\n",
    "c = (np.expand_dims(a, axis=1) * b).sum(axis=1)\n",
    "c = np.einsum('i,ij->i', a, b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor contraction\n",
    "\n",
    "a = $ \\begin{bmatrix} 0 & 1 \\\\ 2 & 3 \\\\ 4 & 5 \\\\ \\end{bmatrix} $，\n",
    "b = $ \\begin{bmatrix} 0 & 1 & 2 \\\\ 3 & 4 & 5 \\\\ 6 & 7 & 8 \\\\ 9 & 10 & 11 \\\\ \\end{bmatrix} $\n",
    "\n",
    "`np.einsum('ki,jk->ij', a, b)`：相同脚标`k`的位置为a的第一维（列方向）、b的第二维（行方向），  \n",
    "相当于 np.tensordot(a,b,axes=(0,1)) 或 a.T @ b.T （np.matmul(a.T, b.T）。\n",
    "\n",
    "参考 [numpy中的tensordot](https://www.cnblogs.com/traditional/p/12639487.html)，其中提供了一些 tensordot 等效的 einsum 表达式写法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor contraction\n",
    "\n",
    "# 2D · 2D\n",
    "a = np.arange(6).reshape((3,2))\n",
    "b = np.arange(12).reshape((4,3))\n",
    "es1 = np.einsum('ki,jk->ij', a, b)\n",
    "print('es1:\\n', es1)\n",
    "# 等效于指定a第一维和b第二维进行tensordot，结果shape=(2,4)\n",
    "tdot1 = np.tensordot(a,b,axes=(0,1))\n",
    "print('tdot1:\\n', tdot1)\n",
    "\n",
    "# 3D · 3D\n",
    "c = np.arange(60.).reshape(3,4,5)\n",
    "d = np.arange(24.).reshape(4,3,2)\n",
    "es2 = np.einsum('ijk,jil->kl', c, d)\n",
    "print('es2:\\n', es2)\n",
    "# 等效于指定c第一、二维和d第二、一维进行tensordot，结果shape=(5,2)\n",
    "tdot2 = np.tensordot(c,d,axes=([0,1],[1,0]))\n",
    "print('tdot2:\\n', tdot2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
